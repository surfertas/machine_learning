{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uninformed Search: \n",
    "\n",
    "Can only generate successors and can only distinguish between a goal state and non-goal state.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{array}{rr}\n",
    "Criterion & BFS & UCS & DFS & DF-Limited & Iterative-D & Bi-D\\\\ \\hline\n",
    "Complete? & Yes^a & Yes^{a,b} & No & No & Yes^a & Yes^{a,d}  \\\\ \\hline\n",
    "Time & O(bd) & O(b^{1+\\lfloor{\\frac{C^*}{\\epsilon}}}) & O(b^m) & O(b^l) & O(b^d) & O(b^{d/2})  \\\\ \\hline\n",
    "Space & O(bd) & O(b^{1+\\lfloor{\\frac{C^*}{\\epsilon}}}) & O(bm) & O(bl) & O(bd) & O(b^{d/2})  \\\\ \\hline\n",
    "Optimal? & Yes^c & Yes & No & No & Yes^c & Yes^{c,d} \\\\ \\hline\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of tree-search strategies. \\\\(b\\\\) is the branching factor. \\\\(d\\\\) is the depth of the shallowest solution. \\\\(m\\\\) is the maximum depth of the search tree. \\\\(l\\\\) is the depth limit.\n",
    "Superscript caveats are as follows:\n",
    "\\\\(^a\\\\) complete if \\\\(^b\\\\) is finite.\n",
    "\\\\(^b\\\\) complete if step costs \\\\(\\geq \\epsilon \\\\) for positive \\\\(\\epsilon\\\\),\n",
    "\\\\(^c\\\\) optimal if step costs are all identical \\\\(^d\\\\) if both directions use breadth-first search.\n",
    "\n",
    "Note: Table from AIMA Figure 3.21 pg.91"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DFS\n",
    "In depth-first search the idea is to travel as deep as possible from neighbour to neighbour before backtracking. \n",
    "What determines how deep is possible is that you must follow edges, and you don't visit any vertex twice.\n",
    "\n",
    "Resources:\n",
    "1. http://www.cs.toronto.edu/~heap/270F02/node36.html\n",
    "2. https://en.wikipedia.org/wiki/Depth-first_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFS(G,v):\n",
    "    stack = [] # start with empty stack (LIFO frontie)\n",
    "    for u in all_vertices:\n",
    "        visited[u] = False\n",
    "    stack.append(v)\n",
    "    while not S: # while S not empty\n",
    "        u = S.pop\n",
    "        if visited[u] == False:\n",
    "            visited[u] == True\n",
    "            for w in u.neighbors:\n",
    "                stack.append(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BFS\n",
    "It starts at the tree root (or some arbitrary node of a graph, sometimes referred to as a 'search key'[1]) and explores the neighbor nodes first, before moving to the next level neighbours. Uses Queue (FIFO), as opposed to stack(LIFO) for DFS\n",
    "\n",
    "Complete: guaranteed to find a goal state if one exists. (DFS is not complete. e.g considered an infinitely large graph, the algorithm would searh depth wise, and if goal not in the path of the first traversal, will infinitely search down the respective path.)\n",
    "\n",
    "Algorithm similar to DFS: \n",
    "1. Just replace stack(LIFO) with queue(FIFO):\n",
    "2. It checks whether a vertex has been discovered before enqueueing the vertex rather than delaying this check until the vertex is dequeued from the queue.\n",
    "\n",
    "Resources:\n",
    "1. https://en.wikipedia.org/wiki/Breadth-first_search\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterative deepening depth-first search\n",
    "\n",
    "1. Iterative deepening search often used in combination with depth-first tree search, that finds the best depth limit. It does this by gradually increasing the limit—first 0, then 1, then 2, and so on—until a goal is found.\n",
    "2. Combines benefit of DFS and BFS\n",
    "3. In general iterative deepening is the preferred uninformed search method when the search space is large, and the depth of the solution is not known.\n",
    "\n",
    "Resources:\n",
    "1. https://www.geeksforgeeks.org/iterative-deepening-searchids-iterative-deepening-depth-first-searchiddfs/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bi-directional breadth-first search\n",
    "\n",
    "1. Run two simultaneous searches - one forward from the initial state and one backward from the goal.\n",
    "2. Hope is that \\\\(b^{\\frac{d}{2}} + b^{\\frac{d}{2}} \\leq b^d\\\\)\n",
    "\n",
    "Resources:\n",
    "1. https://en.wikipedia.org/wiki/Bidirectional_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Informed Search: \n",
    "\n",
    "Strategies that know whether if one state is more promising than another state. \n",
    "\n",
    "#### Conditions for optimality:\n",
    "\n",
    "Admissibility: a heuristic that never overestimates the cost to goal.\n",
    "\n",
    "Consistency (Monotonicity): applicable to A* for graph search. \\\\[h(n) \\leq c(n,a,n') + h(n')\\\\]. This is a form of general triangle inequality. The inequality states that a heuristic \\\\(h(n)\\\\) is consistent if, for every node \\\\(n\\\\) and every successor \\\\(n'\\\\) of \\\\(n\\\\) generated by any action \\\\(a\\\\), the estimated cost of reaching the goal from \\\\(n\\\\) is no greater than the step cost of getting \\\\(n'\\\\) plus the estimated cost of reaching the goal from \\\\(n'\\\\)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A*\n",
    "\"Typical implementations of A* use a priority queue to perform the repeated selection of minimum (estimated) cost nodes to expand. This priority queue is known as the open set or fringe. At each step of the algorithm, the node with the lowest f(x) value is removed from the queue, the f and g values of its neighbors are updated accordingly, and these neighbors are added to the queue. The algorithm continues until a goal node has a lower f value than any node in the queue (or until the queue is empty).The f value of the goal is then the length of the shortest path, since h at the goal is zero in an admissible heuristic.\" -Wiki\n",
    "\n",
    "Heuristics:\n",
    "1. Manhattan distance: https://en.wikipedia.org/wiki/Taxicab_geometry\n",
    "2. Diagonal distance\n",
    "3. Euclidean distance\n",
    "4. Hamming distance: https://en.wikipedia.org/wiki/Hamming_distance\n",
    "\n",
    "Admissable: a heuristic function is said to be admissible if it never overestimates the cost of reaching the goal, i.e. the cost it estimates to reach the goal is not higher than the lowest possible cost from the current point in the path.\n",
    "\n",
    "Selecting Heuristic: One strategy to find an appropriate heuristic is by defining the constraints. Once the constraints are defined, start relaxing constraints, and find a heuristic that can solve the relaxed game.\n",
    "\n",
    "Resources:\n",
    "1. http://www.cs.tau.ac.il/~haimk/papers/alenex06.pdf\n",
    "2. http://www.cs.princeton.edu/courses/archive/spr06/cos423/Handouts/EPP%20shortest%20path%20algorithms.pdf\n",
    "3. http://theory.stanford.edu/~amitp/GameProgramming/AStarComparison.html\n",
    "4. https://www.cs.princeton.edu/courses/archive/fall06/cos402/papers/korfrubik.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
